{
    "title": {
        "text": {
          "headline": "Moments of Uncertainty",
          "text": "The development of modern statistical thinking. We trace the evolution of statistical thinking from its earliest days to its current applications. Explore how moments of doubt and inquiry led to groundbreaking discoveries in probability and data analysis. We'll delve into the origins of statistical concepts..."
        },
        "background": {
          "url": "./media/row-1-column-1(1).png",
          "alt": "http://ism.uqam.ca/~ism/academics/probability-theory-and-applications/"
        },
        "unique_id": "moments-of-uncertainty"
    },
    "events": [
      {
        "media": {
          "url": "./media/2560px-PLATEAS.jpg",
          "caption": "The remains of the walls of Platea.",
          "credit": "https://en.wikipedia.org/wiki/Plataea#/media/File:PLATEAS.jpg"
        },
        "start_date": {
          "year": "-500"
        },
        "text": {
          "headline": "The Seige of Platea",
          "text": "<p>The historian Thucydides in his <i>History of the Peloponnesian War</i> describes the first recorded use of the mode to reduce uncertainty in a statistical estimate. <br> The Peloponnesian War saw the Peloponnesians besiege Plataea. After their initial attacks failed, the Peloponnesians built a wall around the city to starve the Plataeans into surrender.<br>The Plataeans, running out of food, devised a plan to escape over the enemy's walls. In order to make ladders tall enough, they meticulously calculated the height of the wall by counting the layers of bricks over and over again with many different people, assuming that the majority of the counts would be correct. Under the cover of a stormy night, they scaled the wall and made their way to Athens, with most of the escapees reaching safety.<br>This siege is notable for the Plataeans' innovative escape plan, which involved the careful calculation of the wall's height by counting bricks to ensure the correct length of their ladders. This resourceful approach highlights the importance of reducing uncertainty in estimates, a principle still relevant today.</p>"
        },
        "unique_id": "thucydides"
      },
      {
        "media": {
          "url": "./media/al-Khalil.jpg",
          "caption": "Al-Khalil ibn Ahmad al-Farahidi",
          "credit": "https://en.wikipedia.org/wiki/Al-Khalil_ibn_Ahmad_al-Farahidi"
        },
        "start_date": {
          "year": "700"
        },
        "text": {
          "headline": "The Book of Cryptographic Messages",
          "text": "<p>In the 8th century, a significant advancement in the field of cryptography emerged from the Arab world. Al-Khalil ibn Ahmad al-Farahidi, a renowned Arab philologist, lexicographer, and mathematician, authored a groundbreaking work titled 'Book of Cryptographic Messages' (Kitab al-Mu'amma). While the original manuscript has unfortunately been lost to time, its profound impact on the development of cryptography is evident through the references and accounts of subsequent scholars.<br>Al-Khalil's 'Book of Cryptographic Messages' is celebrated for its pioneering use of permutations and combinations, a mathematical concept that underpins the analysis of possible arrangements of objects. In the context of cryptography, this innovation allowed Al-Khalil to systematically enumerate all possible Arabic words, both with and without vowels. This approach was a significant departure from previous cryptographic methods and laid the groundwork for more sophisticated encryption techniques.<br><br> Broemeling, Lyle D. (1 November 2011). <i>An Account of Early Statistical Inference in Arab Cryptology</i>. The American Statistician. 65 (4): 255–257. doi:10.1198/tas.2011.10191</p>"
        },
        "unique_id": "permutations-and-combinations"
      },
      {
        "media": {
          "url": "./media/Al-kindi_cryptographic.png",
          "caption": "The first page of al-Kindi's manuscript 'On Deciphering Cryptographic Messages'",
          "credit": "https://commons.wikimedia.org/wiki/File:Al-kindi_cryptographic.png"
        },
        "start_date": {
          "year": "900"
        },
        "text": {
          "headline": "Frequency Analysis",
          "text": "<p>In the 9th century, a significant milestone in the field of cryptography was achieved by the renowned Arab polymath,<br>Al-Kindi. His groundbreaking work in cryptanalysis, the study of breaking codes and ciphers, revolutionized the way encrypted messages were deciphered. Al-Kindi's ingenuity led to the development of the first known code-breaking algorithm and the pioneering use of frequency analysis.<br>Al-Kindi's magnum opus in this field, titled 'On Deciphering Cryptographic Messages' (Risala fi Istikhraj al-Kutub al-Mu'amma), provided a comprehensive and detailed exploration of statistics and cryptanalysis. This work established a framework for understanding the statistical properties of language and their application to code-breaking.<br>Frequency analysis, a technique that Al-Kindi is credited with developing, involves analyzing the frequency with which different letters or symbols appear in an encrypted message. By comparing these frequencies to the expected frequencies in the language of the original message, patterns can be identified that reveal the underlying code. This method proved to be a powerful tool for deciphering substitution ciphers, where each letter is replaced with another.<br><br>Singh, Simon (2000). <it>The Code Book</i>. New York City: Anchor Books. pp. 14–20</p>"
        },
        "unique_id": "frequency-analysis"
      },
      {
        "media": {
          "url": "./media/trail_pyx.jpg",
          "caption": "Trial of the Pyx 6 December 1854, Illustrated London News",
          "credit": "https://www.royalmintmuseum.org.uk/journal/history/trial-of-the-pyx/"
        },
        "start_date": {
          "year": "1100"
        },
        "text": {
          "headline": "The Trial of the Pyx",
          "text": "<p>The Trial of the Pyx, first held in the 12th century, is a judicial ceremony in the UK that tests whether newly minted coins are of appopriate dimensions. According to The Dialogus de Scaccario (a medeival English treatise), a 'Master of the Mint' would put aside one coin per ten pounds of new silver. Every three months, a random sample of these coins would be tested against official weight and quality standards.</p>"
        },
        "unique_id": "trial-of-the-pyx"
      },
      {
        "media": {
          "url": "./media/KoebelJ.jpg",
          "caption": "Köbel in 1532"
        },
        "start_date": {
          "year": "1500"
        },
        "text": {
          "headline": "The Mean",
          "text": "<p>For a very long time, the concept of a statistical average was not widely accepted by scientists. The prevailing method at the time was to select the most accurate measurement as the most reliable estimate. Combining multiple measurements, especially across different objects, was seen as counterintuitive and illogical.. Although the idea of the arithmetic mean was used by Ancient Greeks, the generalization of this method to more than two data points was first recorded in the 1500s when Jakob Köbel makes use of an average implicitly in his definition of a 16-foot rod followed by Tycho Brahe, a Danish astronomer, who used it to help minimize errors in his calcuations regarding the locations of celestial bodies.</p>"
        },
        "unique_id": "the-mean"
      },
      {
        "media": {
          "url": "./media/Certaine Errors in Navigation.jpg",
          "caption": "Excerpt from Edward Wright's Certaine Errors in Navigation"
        },
        "start_date": {
          "year": "1599"
        },
        "text": {
          "headline": "The Median",
          "text": "<p>The concept of the 'median' was first recorded in 1599, in the publication of 'Certaine Errors in Navigation,' a book on navigation by mathematical Edward Wright. In this book, Edward argued that the median was the 'most correct' observation in a dataset.</p>"
        },
        "unique_id": "the-median"
      },
      {
        "media": {
          "url": ".media/Blaise_Pascal_Versailles.JPG",
          "caption": "Blaise Pascal",
          "credit": "https://en.wikipedia.org/wiki/Blaise_Pascal"
        },
        "start_date": {
          "year": "1654"
        },
        "text": {
          "headline": "Probability Theory",
          "text": "<p>In 1654, a pivotal moment in the history of mathematics occurred as two brilliant minds, Blaise Pascal and Pierre de Fermat, engaged in a series of correspondences that would lay the foundation for the mathematical theory of probability. Their collaboration, sparked by a gambling problem, called the division of the stakes, posed by a French nobleman, Chevalier de Méré, led to groundbreaking insights into the nature of chance and uncertainty.<br>The problem that ignited their intellectual exchange involved the fair division of stakes in an unfinished game of chance. Through their letters, Pascal and Fermat developed a systematic approach to analyzing such problems, introducing concepts such as expected value and probability distributions. They tackled questions like calculating the odds of winning a specific number of coin tosses or rolling a particular number on a die.</p>"
        },
        "unique_id": "probability-theory"
      },
      {
        "media": {
          "url": "./media/Sex_ratio_total_population_per_country_.png",
          "caption": "Sex ratio by country for total population. Blue represents more men and boys, red more women and girls than the world average of 1.01 males/female.",
          "credit": "https://en.wikipedia.org/wiki/Human_sex_ratio"
        },
        "start_date": {
          "year": "1710"
        },
        "text": {
          "headline": "The <i>p</i>-Value",
          "text": "<p>One of the first appearances of what is now known as the <i>p</i>-value was in 1710, when Scottish physician John Arbuthnot studied the human sex ratio. After realizing that the number of males born in London exceeded that of females born for 82 years in a row (1629 - 1710), he calculated that the probability of this naturally occurring was 1 in 4,8360,0000,0000,0000,0000,0000. This was the first recorded use of the  <i>p</i>-value, a measure of the strength of evidence against the null hypothesis. The  <i>p</i>-value is a crucial concept in hypothesis testing and statistical inference, providing a quantitative assessment of the likelihood of observing a particular result under the assumption that the null hypothesis is true. Arbuthnot's pioneering work laid the groundwork for the development of statistical hypothesis testing and the  <i>p</i>-value as a key tool in scientific research.</p>"
        },
        "unique_id": "the-p-value"
      },
      {
        "media": {
          "url": "./media/ArsConjectandi.jpg",
          "caption": "First edition of Bernoulli's Ars Conjectandi",
          "credit": "PMM 179. DSB II, 50. Dibner 110. Evans 8. Grolier/Horblit 12. Sparrow 21. Norman 216. OCLC 10851120. Goldsmiths'-Kress 05090.0."
        },
        "start_date": {
          "year": "1713"
        },
        "text": {
          "headline": "The Law of Large Numbers",
          "text": "<p>In 1713, eight years after his death, the seminal work of Jacob Bernoulli, 'Ars Conjectandi' (The Art of Conjecturing), was posthumously published. This influential book solidified Bernoulli's position as a pioneer in the field of probability theory and introduced a groundbreaking concept known as the law of large numbers.<br>'Ars Conjectandi' was a culmination of Bernoulli's lifelong study of probability and combinatorics. It compiled and expanded upon earlier works by mathematicians such as Christiaan Huygens, Gerolamo Cardano, Pierre de Fermat, and Blaise Pascal, incorporating their insights into a unified framework.<br>The law of large numbers states that as the number of trials or observations of a random event increases, the observed average of the outcomes will tend to converge towards the expected value. In simpler terms, the more times you flip a coin, the closer the proportion of heads and tails will get to 50/50.</p>"
        },
        "unique_id": "the-law-of-large-numbers"
      },
      {
        "media": {
          "url": "./media/ceres.jpg",
          "caption": "Friedrich's sketch of the orbits of the Ceres and Pallas.",
          "credit": "Skizze der Bahnen der Kleinplaneten Ceres, Pallas und Vesta. “Astronomische Untersuchen und Rechnungen vornehmlich ber die Ceres Ferdinandea,” 1802. SUB G¨ottingen: Cod. Ms. Gauß Handbuch 4, Bl. 1."
        },
        "start_date": {
          "year": "1801"
        },
        "text": {
          "headline": "Least Squares",
          "text": "<p>n 1801, a remarkable feat of mathematical and astronomical ingenuity took place when Carl Friedrich Gauss, a young German mathematician, successfully predicted the orbit of the dwarf planet Ceres. Ceres had been briefly observed by Italian astronomer Giuseppe Piazzi before disappearing behind the sun, leaving astronomers puzzled about its trajectory.<br>Gauss, using only a limited set of observational data, applied a novel approach to determine Ceres' orbit. He employed a method known as the line of best fit, a statistical technique that involves finding a straight line that minimizes the overall distance between the line and a set of data points. By applying this method to the available observations of Ceres, Gauss was able to accurately predict its future position, leading to its rediscovery by other astronomers later that year.<br>Five years later, in 1805, French mathematician Adrien-Marie Legendre introduced a more refined method for fitting curves to data, known as the method of least squares. This technique generalizes the concept of the line of best fit to curves of any shape, allowing for more accurate modeling of complex phenomena.</p>"
        },
        "unique_id": "least-squares"
      }
    ]
}